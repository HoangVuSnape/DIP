# -*- coding: utf-8 -*-
"""232805404_521H0517

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VvuhTaQt2qmHS8ahaR9CjfwQKrBT_Cge
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

from google.colab import drive
drive.mount('/content/drive')

image_path = '/content/drive/My Drive/Colab Notebooks/XLA/input.png'
path ='/content/drive/My Drive/Colab Notebooks/XLA/'

def contour_processing(x, y, width, height, image):
    """
    Objective: Process contours to handle various scenarios such as small dots, lines, and bounding boxes.

    Parameters:
    - x, y : int
        The coordinates of the top-left corner of the rectangle.
    - width : int
        Width of the rectangle.
    - height : int
        Height of the rectangle.
    - image : np.ndarray
        The image on which to draw the rectangles.

    Returns:
    None
    """
    global TIMES

    # Ignore small dots
    if height < 40:
        return

    # Ignore lines
    if width > 200:
        return

    # Handle bounding boxes that contain two digits
    if width > 65:
        width_half = width // 2
        x_half = x + width_half
        cv2.rectangle(image, (x, y), (x_half, y + height), (0, 255, 0), 2)
        cv2.rectangle(image, (x_half, y), (x + width, y + height), (0, 255, 0), 2)
        return

    # Handle bounding boxes for 5, 3, and 8 in the bottom right image
    if 40 < width < 60:
        if TIMES == 0:  # Number 8
            cv2.rectangle(image, (x + 10, y), (x + width, y + height), (0, 255, 0), 2)
        elif TIMES == 1:  # Number 3
            cv2.rectangle(image, (x, y), (x + width - 10, y + height-5), (0, 255, 0), 2)
        elif TIMES == 2:  # Number 5
            cv2.rectangle(image, (x, y), (x + width - 10, y + height), (0, 255, 0), 2)

        TIMES += 1
    else:
        cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)

def separate_image(image):
    """
    Objective: Separate the input image into four quadrants.

    Parameters:
    - image : np.ndarray
        The input image to be separated.

    Returns:
    tuple of np.ndarray
        The four separated quadrants of the image: top_left, top_right, bottom_left, bottom_right.
    """
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    height, width = image_gray.shape

    # Cutting coordinates
    cut_x = 226
    cut_y = 270

    # Separate the image into 4 parts
    top_left = image_gray[0:cut_y, 0:cut_x]
    top_right = image_gray[0:cut_y, cut_x:width]
    bottom_left = image_gray[cut_y:height, 0:cut_x]
    bottom_right = image_gray[cut_y:height, cut_x:width]

    return top_left, top_right, bottom_left, bottom_right

def top_left_preprocessing(top_left):
    """
    Objective: Preprocess the top-left quadrant of the image.

    Parameters:
    - top_left : np.ndarray
        The top-left quadrant of the image.

    Returns:
    np.ndarray
        The preprocessed top-left quadrant of the image.
    """
    # Thresholding image
    _, image_binary = cv2.threshold(top_left, 150, 255, cv2.THRESH_BINARY_INV)

    # Use morphological transformations to enhance image clarity
    kernel = np.ones((2, 2))
    image_processed = cv2.morphologyEx(image_binary, cv2.MORPH_DILATE, kernel, iterations=2)

    plt.subplot(1, 2, 1)
    plt.title('image_binary')
    plt.imshow(image_binary, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.title('image_dilated')
    plt.imshow(image_processed, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    return image_processed

def top_right_preprocessing(top_right):
    """
    Objective: Preprocess the top-right quadrant of the image.

    Parameters:
    - top_right : np.ndarray
        The top-right quadrant of the image.

    Returns:
    np.ndarray
        The preprocessed top-right quadrant of the image.
    """
    # Thresholding image
    _, image_binary = cv2.threshold(top_right, 50, 255, cv2.THRESH_BINARY_INV)

    # Use morphological transformations to enhance image clarity
    kernel = np.ones((1, 1))
    image_opened = cv2.morphologyEx(image_binary, cv2.MORPH_OPEN, kernel)
    image_processed = cv2.morphologyEx(image_opened, cv2.MORPH_DILATE, kernel)

    plt.subplot(1, 3, 1)
    plt.title('image_binary')
    plt.imshow(image_binary, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.title('image_opened')
    plt.imshow(image_opened, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.title('image_dilated')
    plt.imshow(image_processed, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    return image_processed

def bottom_left_preprocessing(bottom_left):
    """
    Objective: Preprocess the bottom-left quadrant of the image.

    Parameters:
    - bottom_left : np.ndarray
        The bottom-left quadrant of the image.

    Returns:
    np.ndarray
        The preprocessed bottom-left quadrant of the image.
    """

    # Apply adaptive thresholding to invert the image
    thresholded = cv2.adaptiveThreshold(bottom_left, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)

    # Define a horizontal kernel for morphological operations to detect long horizontal lines
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
    detect_lines = cv2.morphologyEx(thresholded, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)

    # The detected lines are white (255), we want to make them black (0)
    mask_lines_black = cv2.bitwise_not(detect_lines)

    # Apply the mask to the thresholded image, turning only the detected lines black
    result = cv2.bitwise_and(thresholded, mask_lines_black)

    kernel = np.ones((2, 2))
    image_opened = cv2.morphologyEx(result, cv2.MORPH_OPEN, kernel)

    kernel = np.ones((3, 3))
    image_processed = cv2.morphologyEx(image_opened, cv2.MORPH_DILATE, kernel)

    plt.subplot(2, 2, 1)
    plt.title('image_binary')
    plt.imshow(thresholded, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 2)
    plt.title('image after remove lines')
    plt.imshow(result, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 3)
    plt.title('image_opened')
    plt.imshow(image_opened, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 4)
    plt.title('image_dilated')
    plt.imshow(image_processed, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    return image_processed

def bottom_right_preprocessing(bottom_right):
    """
    Objective: Preprocess the bottom-right quadrant of the image.

    Parameters:
    - bottom_right : np.ndarray
        The bottom-right quadrant of the image.

    Returns:
    np.ndarray
        The preprocessed bottom-right quadrant of the image.
    """
    # Thresholding image
    _, image_binary = cv2.threshold(bottom_right, 25, 255, cv2.THRESH_BINARY_INV)

    kernel = np.ones((2, 2))
    image_dilated1 = cv2.morphologyEx(image_binary, cv2.MORPH_DILATE, kernel, iterations=1)

    kernel = np.ones((3, 3))
    image_eroded = cv2.erode(image_dilated1, kernel, iterations=1)

    kernel = np.ones((2, 2))
    image_processed = cv2.morphologyEx(image_eroded, cv2.MORPH_DILATE, kernel, iterations=1)

    plt.subplot(2, 2, 1)
    plt.title('image_binary')
    plt.imshow(image_binary, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 2)
    plt.title('image_dilated')
    plt.imshow(image_dilated1, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 3)
    plt.title('image_eroded')
    plt.imshow(image_eroded, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 4)
    plt.title('image_dilated')
    plt.imshow(image_processed, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    return image_processed

if __name__ == "__main__":

    TIMES = 0
    image_original = cv2.imread(image_path)
    top_left, top_right, bottom_left, bottom_right = separate_image(image_original)

    print("Original, after seperate 4 pictures-------------------------------")
    plt.subplot(2, 2, 1)
    plt.title('Top Left')
    plt.imshow(top_left, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 2)
    plt.title('Top Right')
    plt.imshow(top_right, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 3)
    plt.title('Bottom left')
    plt.imshow(bottom_left, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 4)
    plt.title('Bottom right')
    plt.imshow(bottom_right, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    # Processed
    print("\n\n Top left processed,-------------------------------")
    top_left_processed = top_left_preprocessing(top_left)

    print("\n\n Top right processed,-------------------------------")
    top_right_processed = top_right_preprocessing(top_right)

    print("\n\n Bottom left processed,-------------------------------")
    bottom_left_processed = bottom_left_preprocessing(bottom_left)

    print("\n\n Bottom right processed,-------------------------------")
    bottom_right_processed = bottom_right_preprocessing(bottom_right)

    print("\n\n Four pictures processed,-------------------------------")
    # Print 4 pictures after processed
    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    plt.title('Top Left')
    plt.imshow(top_left_processed, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 2)
    plt.title('Top Right')
    plt.imshow(top_right_processed, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 3)
    plt.title('Bottom left')
    plt.imshow(bottom_left_processed, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 4)
    plt.title('Bottom right')
    plt.imshow(bottom_right_processed, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()


    # Combine 4 images after preprocessing
    top_combined = cv2.hconcat([top_left_processed, top_right_processed])
    bottom_combined = cv2.hconcat([bottom_left_processed, bottom_right_processed])

    # Concatenate images vertically
    result = cv2.vconcat([top_combined, bottom_combined])

    # Display the result
    print("\n\n Combine 4 images,-------------------------------")
    cv2_imshow(result)

    # Find contours from the processed image
    contours, _ = cv2.findContours(result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Process contours one by one
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        contour_processing(x, y, w, h, image_original)

    print("\n\n Result,-------------------------------")
    plt.title('Result')
    plt.imshow(image_original)
    cv2.imwrite(path+"output.jpg", image_original)
    cv2.waitKey(0)