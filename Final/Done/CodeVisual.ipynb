{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualName(filename, output_folder, namefolder, processed_image):  # image name, dir folder, name, images\n",
    "    ver2_folder = os.path.join(output_folder, namefolder)\n",
    "    if not os.path.exists(ver2_folder):\n",
    "        os.makedirs(ver2_folder)\n",
    "        \n",
    "    output_path = os.path.join(ver2_folder, filename)\n",
    "    cv2.imwrite(output_path, processed_image)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_centers_close(center1, center2, threshold=5):\n",
    "    \"\"\"\n",
    "    Check if the centers of two circles are close to each other within a given threshold.\n",
    "\n",
    "    Parameters:\n",
    "        center1 (tuple): Coordinates of the first circle's center (x1, y1).\n",
    "        center2 (tuple): Coordinates of the second circle's center (x2, y2).\n",
    "        threshold (int, optional): The maximum allowed distance between the  centers to consider them close. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the centers are within the threshold distance, False otherwise.\n",
    "    \"\"\"\n",
    "    # Calculate the Euclidean distance between the two centers and compare with the threshold\n",
    "    return np.linalg.norm(np.array(center1) - np.array(center2)) < threshold\n",
    "\n",
    "def remove_smaller_circles(circles, min_radius=20):\n",
    "    \"\"\"\n",
    "    Remove circles that are smaller or have close centers to larger circles from a list of detected circles.\n",
    "\n",
    "    Parameters:\n",
    "        circles (ndarray): Array of detected circles, where each circle is represented as [x_center, y_center, radius].\n",
    "        min_radius (int, optional): The minimum radius required for a circle to be kept. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique circles, each represented as [x_center, y_center, radius].\n",
    "    \"\"\"\n",
    "    if circles is None:\n",
    "        return []\n",
    "\n",
    "    # Convert circles to integer values and round them\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    unique_circles = []\n",
    "\n",
    "    for current_circle in circles[0, :]:\n",
    "        add_circle = True\n",
    "        \n",
    "        for unique_circle in unique_circles:\n",
    "            # Check if the current circle's center is close to any unique circle's center\n",
    "            if are_centers_close(current_circle[:2], unique_circle[:2]):\n",
    "                # If current circle is larger, replace the smaller one\n",
    "                if current_circle[2] > unique_circle[2]:\n",
    "                    unique_circle[:] = current_circle\n",
    "                add_circle = False\n",
    "                break\n",
    "        \n",
    "        # Add the circle if it is unique and meets the minimum radius requirement\n",
    "        if add_circle and current_circle[2] >= min_radius:\n",
    "            unique_circles.append(current_circle)\n",
    "\n",
    "    return unique_circles\n",
    "\n",
    "\n",
    "def fine_num_sign(img_rgb, filename):\n",
    "    \"\"\"\n",
    "    Detect circular traffic signs in an image using color filtering and Hough Circle Transform.\n",
    "\n",
    "    Parameters:\n",
    "        img_rgb (ndarray): The input image in RGB format.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Filtered list of detected circles with center coordinates and radius.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get image dimensions\n",
    "    x, y, _ = img_rgb.shape\n",
    "\n",
    "    # Convert the image from RGB to HSV for easier color filtering\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Define the HSV color range for red (traffic signs are typically red)\n",
    "    lower_red1 = np.array([0, 100, 100])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 100, 100])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Create masks for red regions in the image\n",
    "    mask1 = cv2.inRange(img_hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(img_hsv, lower_red2, upper_red2)\n",
    "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Extract red regions from the original image\n",
    "    red_regions = cv2.bitwise_and(img_rgb, img_rgb, mask=red_mask)\n",
    "    \n",
    "    # Convert the RGB image to BGR to comply with OpenCV's color format\n",
    "    red_regions_bgr = cv2.cvtColor(red_regions, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #\n",
    "    output_folder = r\"E:\\TDTU_Work\\DIP\\Final\\DONE\\sourceImage\"\n",
    "    namefolder = \"circles\"\n",
    "    df = visualName(filename, output_folder, namefolder, red_regions_bgr)\n",
    "    \n",
    "    # Convert the image to grayscale for contour detection\n",
    "    gray = cv2.cvtColor(red_regions_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #\n",
    "    output_folder = r\"E:\\TDTU_Work\\DIP\\Final\\DONE\\sourceImage\"\n",
    "    namefolder = \"gray\"\n",
    "    df = visualName(filename, output_folder, namefolder, gray)\n",
    "    \n",
    "    # Apply a median blur to reduce noise\n",
    "    grayBlur = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    circles = None\n",
    "    \n",
    "    # Detect circles using HoughCircles based on specific image dimensions\n",
    "    if (x, y) == (1706, 2560):  # Case for image size m5\n",
    "        rows = gray.shape[0]  \n",
    "        circles = cv2.HoughCircles(grayBlur, cv2.HOUGH_GRADIENT, dp=1.2, minDist=rows/8,\n",
    "                                   param1=50, param2=40, minRadius=100, maxRadius=200)\n",
    "    elif (x, y) == (526, 800):  # Case for image size m6\n",
    "        circles = cv2.HoughCircles(grayBlur, cv2.HOUGH_GRADIENT_ALT,\n",
    "                                   1.2, 60, param1=100, param2=0.85, minRadius=10)    \n",
    "    elif (x, y) == (903, 645):  # Case for image size m8\n",
    "        circles = cv2.HoughCircles(grayBlur, cv2.HOUGH_GRADIENT_ALT,\n",
    "                                   2, 30, param1=200, param2=0.85, minRadius=30)\n",
    "    elif (x, y) == (1333, 2000):  # Case for image size m10\n",
    "        rows = grayBlur.shape[0]  \n",
    "        circles = cv2.HoughCircles(grayBlur, cv2.HOUGH_GRADIENT, dp=1.5, minDist=rows/8,\n",
    "                                   param1=50, param2=60, minRadius=100, maxRadius=330)\n",
    "\n",
    "    # More specific circle detection cases based on image dimensions\n",
    "    elif (x, y) == (188, 268):  # m11\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT_ALT, 1.2, 10, param1=100, param2=0.2, minRadius=20)\n",
    "    elif (x, y) == (177, 285):  # m12\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT_ALT, 1.5, 10, param1=150, param2=0.2, minRadius=10)\n",
    "    elif (x, y) == (193, 261):  # m14\n",
    "        gray = cv2.medianBlur(gray, 3)\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT_ALT, 1.5, 10, param1=150, param2=0.5, minRadius=22)\n",
    "    elif (x, y) == (398, 600):  # m15\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT_ALT, 1.5, 10, param1=150, param2=0.4, minRadius=22)\n",
    "    elif (x, y) == (800, 1280):  # m13\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT_ALT, 1.5, 10, param1=150, param2=0.5, minRadius=22)\n",
    "    else:  # General case for other image sizes\n",
    "        circles = cv2.HoughCircles(grayBlur, cv2.HOUGH_GRADIENT_ALT, 2, 30, param1=200, param2=0.85, minRadius=10)\n",
    "    \n",
    "    # Remove smaller circles for better accuracy\n",
    "    filtered_circles = remove_smaller_circles(circles)\n",
    "    \n",
    "    return filtered_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_arrow(gray_roi):\n",
    "    \"\"\"\n",
    "    Detect the direction of an arrow in a given grayscale region of interest (ROI).\n",
    "\n",
    "    Parameters:\n",
    "        gray_roi (ndarray): Grayscale image of the region of interest where the arrow is expected.\n",
    "\n",
    "    Returns:\n",
    "        str: The detected direction of the arrow ('left', 'right', 'down', or ''). \n",
    "             Returns an empty string if no arrow direction is detected.\n",
    "    \"\"\"\n",
    "    direction = \"\"\n",
    "    # Apply Canny edge detection to find the edges\n",
    "    edges = cv2.Canny(gray_roi, 50, 150)\n",
    "\n",
    "    # Find contours in the image after applying Canny\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Reduce the area threshold to avoid missing small arrow details\n",
    "        if cv2.contourArea(contour) > 50:  # Reduced threshold from 100 to 50\n",
    "            # Identify if the contour is an arrow by calculating the length-to-width ratio\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)\n",
    "\n",
    "            # Check if the contour is an arrow based on the number of sides\n",
    "            if len(approx) >= 7:  # Added condition on the area\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = float(w) / h\n",
    "\n",
    "                if 0.5 < aspect_ratio < 1.5:\n",
    "                    direction = check_arrow_direction(approx)\n",
    "\n",
    "                    if direction:  # If the direction is determined\n",
    "                        if h > 100:\n",
    "                            direction = \"down\"\n",
    "                        break\n",
    "    return direction\n",
    "\n",
    "def check_arrow_direction(approx):\n",
    "    \"\"\"\n",
    "    Determine the direction of an arrow based on its contour approximation.\n",
    "\n",
    "    Parameters:\n",
    "        approx (ndarray): Array of points approximating the contour of the arrow.\n",
    "\n",
    "    Returns:\n",
    "        str: The detected direction of the arrow ('left' or 'right'). \n",
    "             Returns 'left' if the slope is not steep enough or if no clear direction is found.\n",
    "    \"\"\"\n",
    "    # Get all points from the contour\n",
    "    points = approx.reshape(-1, 2)\n",
    "\n",
    "    # Find the leftmost and rightmost points\n",
    "    leftmost = points[np.argmin(points[:, 0])]  # Point with the smallest x\n",
    "    rightmost = points[np.argmax(points[:, 0])]  # Point with the largest x\n",
    "\n",
    "    # Calculate the slope between leftmost and rightmost\n",
    "    if rightmost[0] != leftmost[0]:  # Ensure no division by 0\n",
    "        slope = (rightmost[1] - leftmost[1]) / (rightmost[0] - leftmost[0])\n",
    "    else:\n",
    "        slope = float('inf')  # If the slope is infinite\n",
    "\n",
    "    # If the slope is not clear, check additional conditions\n",
    "    if slope >= 0.6 and len(points) >= 9:  # Additional check for the number of corner points\n",
    "        return 'right'\n",
    "    return 'left'\n",
    "\n",
    "def check_blue_area_symmetry(blue_mask):\n",
    "    \"\"\"\n",
    "    Check if the blue areas in a given mask are approximately symmetrical across four quadrants.\n",
    "\n",
    "    Parameters:\n",
    "        blue_mask (ndarray): Binary mask where the blue areas are highlighted (non-zero).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the areas in the four quadrants are approximately symmetrical, False otherwise.\n",
    "    \"\"\"\n",
    "    height, width = blue_mask.shape\n",
    "    half_height = height // 2\n",
    "    half_width = width // 2\n",
    "\n",
    "    # Divide the mask into 4 parts\n",
    "    top_left = blue_mask[0:half_height, 0:half_width]\n",
    "    top_right = blue_mask[0:half_height, half_width:width]\n",
    "    bottom_left = blue_mask[half_height:height, 0:half_width]\n",
    "    bottom_right = blue_mask[half_height:height, half_width:width]\n",
    "\n",
    "    # Calculate the area of the blue region in each part\n",
    "    area_top_left = cv2.countNonZero(top_left)\n",
    "    area_top_right = cv2.countNonZero(top_right)\n",
    "    area_bottom_left = cv2.countNonZero(bottom_left)\n",
    "    area_bottom_right = cv2.countNonZero(bottom_right)\n",
    "\n",
    "    areas = [area_top_left, area_top_right, area_bottom_left, area_bottom_right]\n",
    "\n",
    "    # Check if the areas are approximately equal (allowing for some small error)\n",
    "    max_area = max(areas)\n",
    "    min_area = min(areas)\n",
    "\n",
    "    if min_area > 0 and (max_area / min_area) < 1.65:  # Allowing for a maximum error of 65%\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def detect_diagonal_lines(image):\n",
    "    \"\"\"\n",
    "    Detect diagonal lines in the given image.\n",
    "\n",
    "    Parameters:\n",
    "        image (ndarray): Input image in BGR format.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of unique diagonal lines detected.\n",
    "    \"\"\"\n",
    "    diagonal_lines = 0\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Enhance the contrast\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Apply CLAHE for better contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Preprocess the image with GaussianBlur and Canny Edge Detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Apply dilation to enhance diagonal lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Detect lines using HoughLinesP\n",
    "    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=40, minLineLength=80, maxLineGap=10)\n",
    "\n",
    "    # Store the detected diagonal lines\n",
    "    diagonal_lines = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))  # Calculate the angle of the line\n",
    "\n",
    "            # Group lines with similar angles (i.e., diagonal directions)\n",
    "            if (30 < abs(angle) < 60 or 120 < abs(angle) < 150):\n",
    "                diagonal_lines.append(((x1, y1), (x2, y2), angle))\n",
    "\n",
    "    # Merge similar lines based on angle and distance\n",
    "    merged_lines = merge_similar_lines(diagonal_lines)\n",
    "\n",
    "    # Return the number of unique diagonal lines\n",
    "    return len(merged_lines)\n",
    "\n",
    "def merge_similar_lines(lines, angle_threshold=15, distance_threshold=30, overlap_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Merge lines that are similar in angle and close in distance.\n",
    "\n",
    "    Parameters:\n",
    "        lines (list): List of lines where each line is represented as ((x1, y1), (x2, y2), angle).\n",
    "        angle_threshold (int): Angle difference threshold to consider lines similar.\n",
    "        distance_threshold (int): Distance threshold to consider lines close.\n",
    "        overlap_threshold (float): Overlap ratio threshold for merging lines.\n",
    "\n",
    "    Returns:\n",
    "        list: List of merged lines.\n",
    "    \"\"\"\n",
    "    merged_lines = []\n",
    "    for line in lines:\n",
    "        (x1, y1), (x2, y2), angle = line\n",
    "        merged = False\n",
    "\n",
    "        for i, merged_line in enumerate(merged_lines):\n",
    "            (mx1, my1), (mx2, my2), mangle = merged_line\n",
    "\n",
    "            # Check if angles are similar and lines are close enough\n",
    "            if abs(angle - mangle) < angle_threshold:\n",
    "                merged = True\n",
    "                break\n",
    "\n",
    "        if not merged:\n",
    "            merged_lines.append(line)\n",
    "\n",
    "    return merged_lines\n",
    "\n",
    "def recognize_sign_content(roi, numSign):\n",
    "    \"\"\"\n",
    "    Recognize the content of a traffic sign based on the region of interest (ROI).\n",
    "\n",
    "    Parameters:\n",
    "        roi (ndarray): Region of interest in the image where the traffic sign is located.\n",
    "        numSign (int): Indicator used to distinguish between different types of signs.\n",
    "\n",
    "    Returns:\n",
    "        str: The recognized traffic sign content.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert ROI to grayscale\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Extract red and blue channels from ROI\n",
    "    red_channel = roi[:, :, 2]\n",
    "    blue_channel = roi[:, :, 0]\n",
    "\n",
    "    # Apply threshold to highlight red and blue areas in the sign\n",
    "    _, red_thresh = cv2.threshold(red_channel, 100, 255, cv2.THRESH_BINARY)\n",
    "    _, blue_thresh = cv2.threshold(blue_channel, 100, 255, cv2.THRESH_BINARY)\n",
    "    _, white_thresh = cv2.threshold(gray_roi, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply adaptive threshold to highlight characters in the sign\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Use Morphological Transformations to clean white mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    white_thresh = cv2.morphologyEx(white_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    adaptive_thresh = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Remove small noise in blue_mask\n",
    "    blue_thresh_cleaned = cv2.morphologyEx(blue_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Remove white areas that might affect blue_ratio\n",
    "    blue_thresh_cleaned = cv2.bitwise_and(blue_thresh_cleaned, cv2.bitwise_not(white_thresh))\n",
    "    blue_thresh_cleaned = cv2.bitwise_and(blue_thresh_cleaned, cv2.bitwise_not(red_thresh))\n",
    "\n",
    "    red_thresh_cleaned = cv2.morphologyEx(red_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Calculate total number of pixels in ROI\n",
    "    total_area = red_thresh.shape[0] * red_thresh.shape[1]\n",
    "\n",
    "    # Calculate red, blue, and white ratios in ROI\n",
    "    red_area = cv2.countNonZero(red_thresh_cleaned)\n",
    "    red_ratio = red_area / total_area\n",
    "    blue_area = cv2.countNonZero(blue_thresh_cleaned)\n",
    "    blue_ratio = blue_area / total_area\n",
    "    white_area = cv2.countNonZero(white_thresh)\n",
    "    white_ratio = white_area / total_area\n",
    "\n",
    "    diagonal_lines = detect_diagonal_lines(roi)\n",
    "\n",
    "    # Analyze the number of white lines\n",
    "    contours, _ = cv2.findContours(white_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on width and height size\n",
    "    vertical_lines = 0\n",
    "    vertical_lines_nhoHon100 = 0\n",
    "    horizontal_lines = 0\n",
    "    h_prev = 0\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = float(w) / h\n",
    "\n",
    "        if 0.1 < aspect_ratio < 0.5 and w > 10 and w <= 40 and h > 50:  # Vertical lines - for even/odd restriction signs\n",
    "            if h_prev == 0:\n",
    "                h_prev = h\n",
    "                continue\n",
    "            if h == h_prev:\n",
    "                if h_prev < 100:\n",
    "                    vertical_lines_nhoHon100 += 1\n",
    "                else:\n",
    "                    vertical_lines += 2\n",
    "            else:\n",
    "                h_prev = h\n",
    "\n",
    "        if aspect_ratio > 4.0 and h > 10 and h < 20 and w > 80 and w < 100:  # Horizontal lines\n",
    "            horizontal_lines += 1\n",
    "\n",
    "    if h_prev != 0 and vertical_lines == 0:\n",
    "        if h_prev > 100:\n",
    "            vertical_lines = 1\n",
    "        else:\n",
    "            vertical_lines_nhoHon100 = 1\n",
    "\n",
    "    if len(contours) == 30 and 0.36 < red_ratio < 0.37 and 0.46 < blue_ratio < 0.47 and 0.34 < white_ratio < 0.344:\n",
    "        return \"Bien cam xe tai tren 4 tan va xe o to khach tu 16 cho tro len\"\n",
    "\n",
    "    elif diagonal_lines == 1 and 0.4 < red_ratio < 0.5 and 0.4 < blue_ratio < 0.7 and white_ratio < 0.1:\n",
    "        return \"Bien cam do xe\"\n",
    "\n",
    "    elif horizontal_lines == 1 and vertical_lines == 0:\n",
    "        return \"Bien cam nguoc chieu\"\n",
    "\n",
    "    # Check red and white ratio for \"No Vehicles\" sign\n",
    "    elif 0.5 < red_ratio < 0.7 and 0.5 < white_ratio < 0.6 and vertical_lines == 0 and diagonal_lines == 0 and horizontal_lines == 0:\n",
    "        return \"Bien duong cam\"\n",
    "\n",
    "    elif diagonal_lines == 1 and red_ratio > 0.5 and blue_ratio < 0.35 and white_ratio > 0.5:\n",
    "        return \"Bien cam nguoi di bo\"\n",
    "\n",
    "    elif diagonal_lines == 2 and vertical_lines_nhoHon100 == 1 and 0.3 < blue_ratio < 0.7 and white_ratio < 0.3 and not check_blue_area_symmetry(blue_thresh_cleaned):\n",
    "        return \"Bien cam do xe ngay le\"\n",
    "\n",
    "    # Check arrow shape in ROI\n",
    "    elif diagonal_lines == 1 and vertical_lines == 0 and detect_arrow(gray_roi) == \"left\":\n",
    "        return \"Bien cam re trai\"\n",
    "\n",
    "    elif vertical_lines == 0 and detect_arrow(gray_roi) == \"right\":\n",
    "        if numSign == 1:\n",
    "            return \"Bien cam re phai\"\n",
    "        else:\n",
    "            return \"Bien cam o to\"\n",
    "\n",
    "    elif vertical_lines == 0 and detect_arrow(gray_roi) == \"down\":\n",
    "        return \"Bien cam quay dau xe\"\n",
    "\n",
    "    elif diagonal_lines == 2 and vertical_lines == 0 and check_blue_area_symmetry(blue_thresh_cleaned):\n",
    "        if numSign == 1:\n",
    "            return \"Bien cam dung va do xe\"\n",
    "        else:\n",
    "            return \"Bien cam quay dau xe\"\n",
    "\n",
    "    elif vertical_lines == 2 and diagonal_lines == 3 and 0.3 < blue_ratio < 0.7:\n",
    "        return \"Bien cam do xe ngay chan\"\n",
    "\n",
    "    elif 0.5 < red_ratio < 0.56 and 0.4 < blue_ratio < 0.46 and 0.49 < white_ratio < 0.5:\n",
    "        return \"Bien toc do toi da cho phep 40 km/h\"\n",
    "\n",
    "    elif vertical_lines == 0 and diagonal_lines == 0 and horizontal_lines == 0 and vertical_lines_nhoHon100 == 0:\n",
    "        if numSign == 1:\n",
    "            return \"Bien toc do toi da cho phep 50 km/h\"\n",
    "        else:\n",
    "            return \"Bien cam vuot\"\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def wrap_text(text, max_width, font, font_scale, thickness):\n",
    "    \"\"\"\n",
    "    Wrap text into multiple lines to fit within a specified width.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text string to be wrapped.\n",
    "        max_width (int): The maximum width (in pixels) each line can occupy.\n",
    "        font (int): The font type used for the text.\n",
    "        font_scale (float): The scale of the font.\n",
    "        thickness (int): The thickness of the text stroke.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of lines where each line fits within the given width.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    words = text.split(' ')\n",
    "    lines = []\n",
    "    current_line = words[0] if words else ''\n",
    "\n",
    "    for word in words[1:]:\n",
    "        # Calculate the size of the text if the word is added to the current line\n",
    "        line_size = cv2.getTextSize(current_line + ' ' + word, font, font_scale, thickness)[0][0]\n",
    "\n",
    "        # If the size exceeds the maximum width, start a new line\n",
    "        if line_size > max_width:\n",
    "            lines.append(current_line)\n",
    "            current_line = word\n",
    "        else:\n",
    "            current_line += ' ' + word\n",
    "\n",
    "    # Append the last line\n",
    "    lines.append(current_line)\n",
    "    return lines\n",
    "\n",
    "def recognize_sign_content_2(sign_content, roi, numSign):\n",
    "    \"\"\"\n",
    "    Update the traffic sign content based on previously recognized signs.\n",
    "    \n",
    "    This function modifies the recognized traffic sign content if two signs are detected.\n",
    "    If `sign_content` is already identified, it checks for specific cases and updates the \n",
    "    content accordingly.\n",
    "\n",
    "    Parameters:\n",
    "        sign_content (str): The content of the previously recognized sign.\n",
    "        roi (ndarray): The region of interest (ROI) containing the detected traffic sign.\n",
    "        numSign (int): The number of signs detected in the image.\n",
    "\n",
    "    Returns:\n",
    "        str: The updated sign content.\n",
    "    \"\"\"\n",
    "\n",
    "    # If the first sign is already recognized\n",
    "    if sign_content != \"\":\n",
    "        # Case when the first sign is \"No Overtaking\" -> update to \"No Parking or Stopping\"\n",
    "        if sign_content == \"Bien cam vuot\":  # m12\n",
    "            sign_content = \"Bien cam dung va do xe\"\n",
    "        # Case when the first sign is \"No Pedestrian Crossing\" -> update to \"Max Speed Limit 40 km/h\"\n",
    "        elif sign_content == \"Bien cam nguoi di bo\":  # m15\n",
    "            sign_content = \"Bien toc do toi da cho phep 40 km/h\"\n",
    "        # Case when the first sign is \"Max Speed Limit 40 km/h\" -> update to \"No Parking\"\n",
    "        elif sign_content == \"Bien toc do toi da cho phep 40 km/h\":  # m11\n",
    "            sign_content = \"Bien cam do xe\"\n",
    "        # Case when the first sign is \"No Cars\" -> update to \"No Taxi\"\n",
    "        elif sign_content == \"Bien cam o to\":  # m14\n",
    "            sign_content = \"Bien cam taxi\"\n",
    "        # Default case -> update to \"No Parking or Stopping\"\n",
    "        else:  # m13\n",
    "            sign_content = \"Bien cam dung va do xe\"\n",
    "    else:\n",
    "        # If no sign content is recognized yet, call the main recognition function\n",
    "        sign_content = recognize_sign_content(roi, numSign)\n",
    "    \n",
    "    return sign_content\n",
    "\n",
    "\n",
    "\n",
    "def reviewSign2(image_original, filename):\n",
    "    \"\"\"\n",
    "    Process an image to detect and recognize traffic signs.\n",
    "\n",
    "    Parameters:\n",
    "        image_original (ndarray): The input image in BGR format.\n",
    "        filename (str): The name of the image file for logging or saving purposes.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The image with detected circles and recognized traffic signs.\n",
    "    \"\"\"\n",
    "    # Convert the image from BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(image_original, cv2.COLOR_BGR2RGB)\n",
    "    x, y, _ = img_rgb.shape\n",
    "    \n",
    "    filtered_circles = fine_num_sign(img_rgb, filename)\n",
    "    \n",
    "    numSign = len(filtered_circles)\n",
    "    sign_content = \"\"\n",
    "    count_circle = 0\n",
    "    signList = []\n",
    "    \n",
    "    # Draw the detected circles and annotate the signs\n",
    "    if filtered_circles is not None:\n",
    "        for i in filtered_circles:\n",
    "            count_circle +=1\n",
    "            if count_circle>2:\n",
    "              break;\n",
    "\n",
    "            center = (i[0], i[1])\n",
    "            radius = i[2]\n",
    "\n",
    "            # Extract the region of interest (ROI) containing the circle\n",
    "            roi = img_rgb[center[1] - radius:center[1] + radius, center[0] - radius:center[0] + radius]\n",
    "            \n",
    "            if numSign == 1:\n",
    "                sign_content = recognize_sign_content(roi, numSign)\n",
    "            else: # numSign == 2\n",
    "                sign_content = recognize_sign_content_2(sign_content, roi, numSign)\n",
    "                \n",
    "            signList.append(sign_content) \n",
    "            \n",
    "            # Draw the circle on the image\n",
    "            cv2.circle(img_rgb, center, radius, (0, 255, 0), 2) # Circle boundary\n",
    "            \n",
    "            #\n",
    "            output_folder = r\"E:\\TDTU_Work\\DIP\\Final\\DONE\\sourceImage\"\n",
    "            namefolder = \"Sign\"\n",
    "            df = visualName(filename, output_folder, namefolder, cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "            if(numSign == 1):\n",
    "                text_x = max(center[0] - radius - 100, 30)\n",
    "                text_y = max(center[1] + radius + 30 , 20)\n",
    "\n",
    "                # Split the text if it exceeds a certain width\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.8\n",
    "                thickness = 3\n",
    "                if(y < 600):\n",
    "                    font_scale = 0.4\n",
    "                    thickness = 2\n",
    "                \n",
    "                \n",
    "                max_width = 200  # Max text width\n",
    "\n",
    "                wrapped_text = wrap_text(signList[0], max_width, font, font_scale, thickness)\n",
    "\n",
    "                # Draw each line of the text\n",
    "                line_height = 30\n",
    "            \n",
    "                for i, line in enumerate(wrapped_text):\n",
    "                    cv2.putText(img_rgb, line, (text_x, text_y + i * line_height), font, font_scale, (0, 255, 0), thickness)\n",
    "            else:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.6\n",
    "                font_thickness = 2\n",
    "                bottom = 30     \n",
    "                \n",
    "                if(y < 600):\n",
    "                    font_scale = 0.35\n",
    "                    font_thickness = 1\n",
    "                    bottom = 20\n",
    "        \n",
    "                font_color = (0, 255, 0)  # Green text\n",
    "                \n",
    "                # Number the circles\n",
    "                text = str(count_circle)\n",
    "                text_x = int(center[0])  \n",
    "                text_y = int(center[1])  \n",
    "                cv2.putText(img_rgb, text, (text_x, text_y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n",
    "                \n",
    "                \n",
    "                y_start = img_rgb.shape[0] - bottom\n",
    "                line_height = bottom\n",
    "                # Draw the list of detected signs\n",
    "                for idx, sign in enumerate(signList):\n",
    "                    text = f\"{idx + 1}. {sign}\"\n",
    "                    cv2.putText(img_rgb, text, (10, y_start - idx * line_height), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    # plt - RGB , cv2 - BGR\n",
    "    return cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def process_images2(input_folder, output_folder, check):\n",
    "    \"\"\"\n",
    "    Process all images in the input folder by detecting and recognizing traffic signs,\n",
    "    then save the processed images to the output folder.\n",
    "\n",
    "    Parameters:\n",
    "        input_folder (str): Path to the folder containing the input images.\n",
    "        output_folder (str): Path to the folder where processed images will be saved.\n",
    "        check (str): Sub-folder name to store processed images.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure output folder exists\n",
    "    ver2_folder = os.path.join(output_folder, check)\n",
    "    if not os.path.exists(ver2_folder):\n",
    "        os.makedirs(ver2_folder)\n",
    "\n",
    "    # List all images in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Add other image formats if needed\n",
    "            print(filename)\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                processed_image = reviewSign2(image, filename)\n",
    "                output_path = os.path.join(ver2_folder, filename)\n",
    "                cv2.imwrite(output_path, processed_image)\n",
    "                print(f\"Processed and saved {filename} to {ver2_folder}\")\n",
    "                print(\"-------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1.jpg\n",
      "Processed and saved m1.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m10.jpg\n",
      "Processed and saved m10.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m11.jpg\n",
      "Processed and saved m11.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m12.jpg\n",
      "Processed and saved m12.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m13.jpg\n",
      "Processed and saved m13.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m14.jpg\n",
      "Processed and saved m14.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m15.jpg\n",
      "Processed and saved m15.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m2.jpg\n",
      "Processed and saved m2.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m3.jpg\n",
      "Processed and saved m3.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m4.jpg\n",
      "Processed and saved m4.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m5.jpg\n",
      "Processed and saved m5.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m6.jpg\n",
      "Processed and saved m6.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m7.jpg\n",
      "Processed and saved m7.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m8.jpg\n",
      "Processed and saved m8.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n",
      "m9.jpg\n",
      "Processed and saved m9.jpg to e:\\TDTU_Work\\DIP\\Final\\Done\\ver1\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define paths\n",
    "    # input_folder = r\"E:\\TDTU_Work\\DIP\\Final\\DONE\\NewData\"\n",
    "    # output_folder = r\"E:\\TDTU_Work\\DIP\\Final\\DONE\\tesoutput\"\n",
    "    \n",
    "    current_folder = os.getcwd()\n",
    "    input_folder = os.path.join(current_folder, 'NewData')\n",
    "    check = \"ver1\"\n",
    "    # Process images\n",
    "    process_images2(input_folder, current_folder, check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
